<div id="ajax-page" class="ajax-page-content">
    <div class="ajax-page-wrapper">
        <div class="ajax-page-nav">
            <div class="nav-item ajax-page-prev-next">
                <a class="ajax-page-load" href="./these/t_chap5.html"><i class="pe-7s-icon pe-7s-angle-left"></i></a>
                <a class="ajax-page-load" href="./these/t_chap7.html"><i class="pe-7s-icon pe-7s-angle-right"></i></a>
            </div>
            <div class="nav-item ajax-page-close-button">
                <a id="ajax-page-close-button" href="#"><i class="pe-7s-icon pe-7s-close"></i></a>
            </div>
        </div>

        <div class="ajax-page-title">
            <div class="chapter-title"><h2>Chapitre 6 : Définition d'une méthode de conception basée sur la délégation GPU</h2></div>
        </div>

        <div class="row">
            <br/>
            <div class="col-sm-6 col-md-6 subpage-block">
                <ul class="project-general-info">
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap1.html"> Chapitre 1 : Simulation multi-agent</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap2.html"> Chapitre 2 : Calcul haute performance et GPGPU</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap3.html"> Chapitre 3 : Simulations multi-agents et GPGPU</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap4.html"> Chapitre 4 : Le principe de délégation GPU des perceptions agents</a></p></li>
                </ul>
            </div>
            <div class="col-sm-6 col-md-6 subpage-block">
                <ul class="project-general-info">
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap5.html"> Chapitre 5 : Expérimentation du principe de délégation GPU</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap7.html"> Chapitre 7 : Conclusion</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap8.html"> Chapitre 8 : Perspectives de recherche</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_bib.html"> Bibliographie</a></p></li>
                </ul>                
            </div>

            <p>Dans ce chapitre, nous présentons la formalisation de l'approche developpée tout au long de ce manuscrit sous la forme d'une méthode de conception de simulation multi-agents basée sur le principe de délégation GPU [Hermellin-MABS-2016]. Cette méthode, en plus d'instaurer un cadre à l'utilisation de la programmation GPU dans le contexte des simulations multi-agents, se veut différente des autres solutions développées de par le fait qu'elle ne cache pas à l'utilisateur la technologie utilisée (utilisation directe du GPGPU) et qu'elle met en avant un processus de modélisation itératif modulaire prônant la réutilisabilité des outils créés. De plus, nous pensons que définir une telle méthode de conception permettra, en plus de diversifier le champ d'application du principe de délégation GPU, d'accroître la diffusion de l'approche dans la communauté multi-agent et de faciliter son utilisation.</p>

            <p>Enfin, en adéquation avec les enjeux énoncés tout au long de ce manuscrit, la méthode de conception proposée poursuit quatre objectifs majeurs :</p>
            <ul>
            <li><p>simplifier l'utilisation du GPGPU dans le contexte des simulations multi-agents en décrivant le processus de modélisation et d'implémentation à suivre ;</p></li>
            <li><p>définir une approche générique pouvant être appliquée sur une grande variété de modèles ;</p></li>
            <li><p>promouvoir la réutilisabilité des outils créés ou des modèles transformés (par exemple en réutilisant les modules GPU déjà développés) ;</p></li>
            <li><p>aider les utilisateurs potentiels à décider s'ils peuvent bénéficier du GPGPU compte tenu de leurs modèles.</p></li>
            </ul>

            <br/>
            <div class="block-title">
                <h3>Enoncé de la méthode</h3>
            </div>

            <p>Les différentes expérimentations menées jusqu'ici permettent d'extraire une méthode de conception basée sur le principe de délégation GPU et divisée en 5 phases distinctes  [Hermellin-JFSMA-2016, Hermellin-MABS-2016] :</p>
            <ol>
            <li><p>La première étape décompose tous les calculs qui sont utilisés dans le modèle.</p></li>
            <li><p>La deuxième étape identifie, parmi les calculs précédemment listés, ceux répondant aux critères du principe de délégation GPU.</p></li>
            <li><p>La troisième étape consiste à vérifier si les calculs identifiés comme compatibles avec le principe de délégation GPU ont déjà été transformés en dynamiques environnementales et donc s'il existe un module GPU dédié pouvant être réutilisé.</p></li>
            <li><p>La quatrième étape établit la compatibilité des calculs sélectionnés avec l'architecture d'un GPU. L'idée étant de choisir et d'appliquer le principe de délégation uniquement sur les calculs qui vont apporter le plus de gain une fois traduits en modules GPU.</p></li>
            <li><p>Enfin, la cinquième étape consiste à implémenter concrètement le principe de délégation GPU sur les calculs respectant l'ensemble des contraintes précédentes.</p></li>
            </ol>

            <div class="portfolio-page-image">
                <img src="./these/images_chap6/methodology.svg" alt=""/>
            </div>

            <h4>Étape 1 : décomposition des calculs du modèle</h4>

            <p>Cette phase consiste à décomposer tous les calculs qui sont utilisés par le modèle. L'intéret d'une telle décomposition réside dans le fait qu'un certain nombre de calculs présents dans le modèle ne sont pas explicites. Expliciter les calculs nécessaires à la réalisation des différents comportements des agents, en les décomposant en le plus de primitives possibles, va permettre d'augmenter l'efficacité de l'application du principe de délégation GPU sur le modèle considéré. En effet, l'intérêt d'une telle décomposition permet de ne pas avoir un seul "gros" <i>kernel</i> contenant tous les calculs GPU, mais de capitaliser sur l'aspect modulaire et hybride du principe de délégation GPU avec plusieurs <i>kernels</i> très simples mais qui tirent partie de la décomposition des calculs. Chaque calcul (compatible) peut alors prétendre à avoir son propre <i>kernel</i>. Ainsi, la délégation GPU sera d'autant plus efficace qu'il va être possible de décomposer le modèle en calculs "élémentaires". D'ailleurs, dans le contexte de l'utilisation du GPGPU pour les simulations multi-agents, cette décomposition des actions a également été identifiée comme cruciale dans [Coakley2016]. En introduisant une nouvelle division des actions des agents qui limite les accès concurrents aux données, [Coakley2016] montre qu'il a été possible d'augmenter significativement les performances globales des modèles qui utilisent le GPGPU.</p>

            <h4>Étape 2 : identification des calculs compatibles</h4>
            
            <p>L'identification des calculs compatibles est une étape essentielle car elle consiste à vérifier quels sont les calculs qui répondent aux critères du principe de délégation GPU et qui pourront ainsi bénéficier du GPGPU. Dans le cas où aucune partie du modèle n'est conforme aux critères d'application du principe de délégation GPU, il est inutile de continuer à suivre cette méthode car, dans un tel cas, les gains apportés par le GPGPU pourraient être insignifiants voire même négatifs (<i>cf.</i> [Laville2012]). Les conditions permettant d'identifier un calcul comme compatible sont différentes selon si le calcul est présent dans l'environnement ou dans le comportement des agents.</p>

            <p><b>Pour l'environnement</b></p>
            
            <p>Si l'environnement n'est pas statique et qu'il contient des dynamiques, ces dernières doivent (1) s'appliquer sur tout l'environnement et (2) avoir un impact global. En effet, l'impact des dynamiques est un paramètre important. Prenons l'exemple d'une dynamique environnementale qui consiste à faire apparaitre de manière stochastique dans l'environnement, à chaque $x$ pas de temps, une source de nourriture à une position donnée. Cette dynamique va bien s'appliquer sur tout l'environnement mais ne va avoir qu'un impact très localisé. Dans ce cas, traduire cette dynamique dans un module GPU n'est pas justifié car les gains espérés seront nuls (voir négatifs). Dans le cas contraire, si la dynamique possède un impact global et répond à toutes les contraintes énoncées, sa compatibilité est établie et sa traduction en module GPU est alors possible et pertinente.</p>

            <p><b>Pour les agents</b></p>

            <p>Si des calculs de perceptions ne modifient pas les états des agents, ils peuvent être considérés comme compatibles et transformés en dynamiques environnementales pour être implémentés dans des modules GPU indépendants. L'idée est de transformer un calcul de perception réalisé de manière locale en une dynamique environnementale s'appliquant globalement dans l'environnement.</p>

            <h4>Étape 3 : réutilisation des modules GPU existants</h4>
            
            <p>Un des objectifs de la méthode est de promouvoir la réutilisabilité des modules GPU créés. En effet, comme vu précédemment, le principe de délégation GPU sur lequel se base la méthode, se distingue par la création de modules GPU génériques pouvant être réutilisés dans des contextes différents de ceux pour lesquels ils ont été créés. Ainsi, il convient de vérifier que les calculs identifiés précédemment n'aient pas déjà un module GPU dédié. Si c'est le cas, il est possible de le réutiliser et de passer directement à l'étape 5 afin d'adapter les structures de données au module existant.</p>

            <h4>Étape 4 : évaluation de l'adaptation des calculs sur l'architecture des GPU</h4>

            <p>Avant d'appliquer concrètement la délégation GPU sur les calculs identifiés comme compatibles, il est nécessaire d'évaluer si ces calculs vont pouvoir s'adapter à l'architecture massivement parallèle des GPU. En effet, la compatibilité d'un calcul avec les critères du principe de délégation GPU n'implique pas forcement une amélioration des performances une fois ce principe appliqué. Ainsi, comme nous avons pu le constater précédemment, nos différentes expérimentations ont souligné de grosses variations autour des gains de performance obtenus avec même, par moment, des résultats que l'on peut qualifier de médiocres. Dans ces conditions, il est nécessaire d'avoir une estimation même empirique des gains escomptés afin d'évaluer la pertinence d'appliquer la délégation GPU sur les calculs identifiés.</p>

            <p>Cette phase de vérification peut être réalisée en répondant à trois questions :</p>
            <ul>
            <li><p><i>Est-ce que les calculs identifiés vont pouvoir être distribués sur le GPU ?</i><br/> Ces calculs doivent être indépendants et simples et ne pas contenir de trop nombreuses structures conditionnelles, ces dernières pouvant causer des problèmes de divergence des <i>threads</i> (<i>cf.</i> [Sanders2011] en page 78) ou des ralentissements lors de l'exécution. Des calculs contenant des boucles itératives s'adaptent mieux aux architectures parallèles.</p></li>
            <li><p><i>Est-ce que les calculs identifiés sont réalisés de manière globale (par un grand nombre d'agents ou appliqués sur un grand nombre de cellules de l'environnement) ?</i><br/> En raison des coûts très élevés (en temps) qu'occasionnent les transferts de données entre GPU et CPU, des calculs rarement utilisés vont accroitre le temps de calcul général du modèle.</p></li>
            <li><p><i>Est-ce que les structures de données associées aux calculs identifiés vont pouvoir s'adapter aux contraintes d'une utilisation sur GPU ?</i><br/> En l'occurrence, il s'agit principalement de s’assurer que les données peuvent être distribuées sur le GPU (en tenant compte des spécificités des différents types de mémoire) et traitées avec un degré élevé d'indépendance afin d'avoir une implémentation GPU efficace. Pour plus d'informations sur cet aspect, [Bourgoin2013-2] peut être consulté.</p></li>
            </ul>

            <p>Pour donner un exemple, en se basant sur nos différents cas d'étude, il est possible d'utiliser, dans le cas d'environnements discrétisés, des structures de données (des tableaux par exemple) de la taille de l'environnement. Ce qui les rend très adaptées à l'architecture du GPU. En effet, chaque cellule de l'environnement aura ainsi un <i>thread</i> qui lui sera entièrement dédié.</p>

            <div class="portfolio-page-image">
                <img src="./these/images_chap6/GPUdelegation.svg" alt=""/>
            </div>

            <h4>Étape 5 : implémentation du principe de délégation GPU</h4>
            
            <p>Les calculs étant identifiés et évalués, il convient d'appliquer sur chacun d'entre eux la délégation GPU. Cette application est divisée en trois étapes :</p>
            <ol>
            <li><p>Création des modules GPU ;</p></li>
            <li><p>Adaptation des structures de données ;</p></li>
            <li><p>Création des interfaces entre la partie CPU du modèle et les modules GPU.</p></li>
            </ol>

            <p>L'application de la délégation GPU commence par la création des modules GPU contenant les <i>kernels</i> de calculs (la traduction des calculs séquentiels en version parallèle). Grâce à la décomposition effectuée précédemment, ces <i>kernels</i> ne nécessitent que peu de connaissances en GPGPU et tiennent en seulement quelques lignes de code. En général, ces modules sont divisés en quatre parties :</p>
            <ul>
            <li><p>(1) Initialisation du <i>thread</i> qui va effectuer le calcul ;</p></li>
            <li><p>(2) Test conditionnel sur la position du <i>thread</i> dans la grille globale du GPU permettant l'accès aux données correspondantes ;</p></li>
            <li><p>(3) Réalisation du calcul ;</p></li>
            <li><p>(4) Ecriture des résultats.</p></li>
            </ul>

<pre>
/*(1) Initialisation du thread*/
i = blockIdx.x * blockDim.x + threadIdx.x;
j = blockIdx.y * blockDim.y + threadIdx.y;
\ ... \;

/*(2) Test conditionnel sur la taille de la grille de threads*/
Si(i &lt; width et j &lt; height){
    /*(3) Réalisation des calculs*/
    \ ... \;
}

/*(4) Ecriture des résultats*/
</pre>

            <p>Ensuite, les structures de données doivent être adaptées aux modules GPU créés. Cette adaptation est basée sur la nature des calculs effectués et sur le type d'environnement utilisé (des tableaux correspondant à la discrétisation de l'environnement sont le plus souvent utilisés).</p>

            <p>Enfin, ces nouveaux éléments doivent être intégrés et reliés à la partie CPU du modèle. Pour ce faire, de nouvelles versions des fonctions de perceptions qui encapsulent l'utilisation du GPU doivent être créées afin de permettre aux agents et à l'environnement de recueillir et d'utiliser les données calculées par les modules GPU. La plupart du temps, ces fonctions sont de simples primitives d'accès aux données.</p>

            <br/>
            <div class="block-title">
                <h3>Validation de l'approche</h3>
            </div>

            <p>L'édition de cette méthode a représenté une étape importante dans la formalisation du travail mené. Il était cependant nécessaire de l'expérimenter. Nous avons donc choisi de l'appliquer sur deux nouveaux modèles multi-agents : le modèle <i>Heatbugs</i> et Proie-prédateur. Plus précisément, l'application de la méthode sur ces deux modèles a été réalisée de manière à faire apparaître explicitement les 5 étapes du processus afin de pouvoir définir quels sont les avantages et limites d'une telle approche.</p>

            <p>A la suite de chacune des expérimentations, nous avons conduit un test de performance entre les deux versions du modèle (CPU et hybride) en faisant varier la taille de l'environnement ainsi que la densité des agents. Chaque simulation est exécutée plusieurs fois sur une période de 10 000 pas de temps. On calcule ensuite le temps moyen d'exécution pour une itération, nous donnant ainsi une valeur permettant de comparer les deux versions du modèle. Pour ces tests, nous avons réutilisé la même configuration matérielle et logicielle que précédemment. Les codes sources, ressources et vidéos de ces modèles sont aussi disponibles en ligne.</p>

            <h4>Le modèle <i>Heatbugs</i></h4>

            <p><b>Présentation du modèle</b></p>

            <p>Le modèle <i>Heatbugs</i> est un modèle multi-agent bio-inspiré dans lequel des agents tentent de maintenir une température optimale autour d'eux. Plus précisément, ces agents se déplacent dans un environnement à deux dimensions discrétisé en cellules (une cellule ne peut être occupée que par un seul agent) et émettent de la chaleur qui se diffuse dans l'environnement.</p>
            
            <p>Chaque agent possède une température idéale qu'il cherche à atteindre. Ainsi, plus la température de la case sur laquelle il se trouve va être différente de sa température idéale et plus l'agent va être mécontent. Lorsque un agent n'est pas satisfait (sa case est trop froide ou trop chaude), il se déplace aléatoirement pour trouver une place qui correspondra mieux à ces attentes.</p>

            <p><b>Application de la méthode</b></p>

            <p><b>Étape 1.</b> : on décompose les calculs présents dans le modèle.</p>
            <ul>
            <li><p>Dans l'environnement : diffusion de la chaleur (C1).</p></li>
            <li><p>Pour les agents : déplacement (C2), émission de chaleur (C3), calcul des différences de température (C4) et calcul du bonheur (C5).</p></li>
            </ul>

            <div class="portfolio-page-image">
                <img src="./these/images_chap6/heatbugs.svg" alt=""/>
            </div>

            <p><b>Étape 2.</b> : parmi les 5 calculs présents dans le modèle, on identifie maintenant ceux qui sont compatibles avec les critères du principe de délégation GPU. C1 est une dynamique globale de l'environnement (une diffusion d'information, ici la chaleur) qui ne contient aucun processus décisionnel. Cette dynamique s'applique sur tout l'environnement et possède un impact global : elle est donc compatible avec les critères du principe. C4 consiste à percevoir la température de la case sur laquelle se trouve l'agent et calculer la différence entre cette température et la température idéale de l'agent. Ce calcul ne modifie pas les états de l'agent, il est donc compatible avec le principe et peut être transformé en une dynamique environnementale. Cependant, les calculs C2, C3 et C5 modifient les états des agents, on ne les considère donc pas pour la suite.</p>

            <p><b>Étape 3.</b> : seuls C1 et C4 sont identifiés comme compatibles avec le principe de délégation GPU. Le calcul C4 n'a pour l'instant jamais été implémenté dans un module GPU à la différence de C1 qui consiste en une diffusion (de chaleur) et qui a déjà été effectuée plusieurs fois (dans le cas d'étude sur le modèle MLE, et le modèle <i>Fire</i>). On réutilise donc le module GPU correspondant à ce calcul.</p>

            <p><b>Étape 4.</b> : C1 étant un calcul compatible déjà utilisé dans plusieurs modèles, il n'est pas nécessaire d'évaluer son adaptation sur l'architecture des GPU. Cependant, C4 étant réalisé pour la première fois, il est nécessaire d'effectuer cette phase de vérification. Ainsi, C4 consiste en la réalisation d'une différence, il peut être facilement distribué sur la grille de <i>threads</i> du GPU (chaque <i>thread</i> va réaliser cette opération sur les données correspondant à sa position dans la grille). De plus, tous les agents calculent cette différence à chaque pas de simulation. Transformer ce calcul est donc pertinent car réalisé de très nombreuses fois. Enfin, les données utilisées pour ce calcul peuvent être stockées dans des tableaux s'adaptant parfaitement aux contraintes des architectures GPU.</p>

            <p><b>Étape 5.</b> : Suite aux 4 étapes précédentes, on peut appliquer le principe de délégation GPU sur C1 et C4 qui remplissent toutes les exigences requises.</p>

            <p>Pour C1, le module GPU <i>Diffusion</i> est réutilisé, seules les données envoyées nécessitent d'être adaptées. Dans ce modèle, les données relatives à la chaleur sont stockées dans un tableau à une dimension (<i>heatArray</i>, correspondant à la taille de l'environnement) dans lequel les agents déposent, en fonction de leur position, la quantité de chaleur qu'ils émettent à chaque pas de simulation. Ce tableau est ensuite envoyé au GPU qui calcule simultanément la diffusion de la chaleur pour toutes les cellules de l'environnement. Plus précisément, pour chaque cellule, un <i>thread</i> calcule la somme de la chaleur des cellules voisines qui est ensuite modulée par une variable de diffusion.</p>

            <p>Après l'exécution du module GPU <i>Diffusion</i>, la chaleur de chaque cellule est utilisée pour calculer la différence entre cette valeur et la température idéale de l'agent qui se trouve sur la cellule. Cette différence calculée au départ dans le comportement des agents est maintenant réalisée dans une dynamique environnementale pour tout l'environnement. Plus précisément, chaque agent dépose, en fonction de sa position, sa température idéale dans un tableau à une dimension (<i>idealTemperatureArray</i>, correspondant à la taille de l'environnement). Les deux tableaux sont envoyés au GPU qui effectue le calcul de la différence. Les agents utilisent ensuite ces résultats pour calculer leur valeur de bonheur, à partir d'une perception pré-calculée par un <i>kernel</i> GPU.</p>

<pre>
i = blockIdx.x * blockDim.x + threadIdx.x;
j = blockIdx.y * blockDim.y + threadIdx.y;
diff = 0;

Si(i &lt; width et j &lt; height){
    diff = heatArray[convert1D(i,j)] - idealTemperatureArray[convert1D(i,j)];
}

resultDiffArray[convert1D(i,j)] = diff;
</pre>

            <p>Le <i>kernel</i>, a mené à la création d'un nouveau module GPU nommé <i>Différence</i>. Il faut noter qu'enchaîner l'exécution de ces deux modules permet d'éviter des transferts de données coûteux et inutiles qui occasionneraient des baisses importantes de performance lors de l'exécution de la simulation. Dans notre cas, le module <i>Différence</i> réutilise les données tout juste calculées par le module <i>Diffusion</i> et qui sont toujours présentes dans la mémoire du GPU.</p>

<pre>
Tantque(simu){
    /*Activation des agents*/
    Pour(agent dans listOfAgents){
        computeHapiness(resultDiffArray[]);
        live();
        fillHeatArray(heatArray[]);
    }

    /*Activation de l'environnement*/
    executeGPUKernel( Diffusion(heatArray[]) );
    executeGPUKernel( Différence(heatArray[], idealTemperatureArray[]) );
}
</pre>

            <p><b>Performance du modèle</b></p>

            <p>Pour tester les performances du modèle <i>Heatbugs</i>, nous avons simulé successivement les versions CPU et hybride pour des environnements de taille 256, 512, 1 024 et 2 048. Pour chacune de ces tailles d'environnement, nous avons fixé la densité des agents à 40 %.</p>

            <div id="chart_chap6_1" class="chart"></div>

            <p>Des graphiques, on observe que le gain de performance obtenu pour le temps d'exécution de l'environnement est d'autant plus important que l'environnement est grand. Cependant, les temps d'exécution correspondant au calcul des agents reste faible (environ 5 %). Ces résultats s'expliquent de la façon suivante : la dynamique de diffusion (C1) est appliquée à toutes les cellules et profite donc grandement de la puissance du GPU alors que seule une petite partie des calculs effectués par les agents a été transformée (C4). Ainsi, la partie séquentielle des comportements des agents brident les performances globales du modèle.</p>

            <h4>Le modèle Proie-prédateur</h4>

            <p><b>Présentation du modèle</b></p>
            
            <p>Proposé indépendamment par Alfred James Lotka en 1925 [Lotka1925] et Vito Volterra en 1926 [Volterra1926], le modèle Proie-prédateur est aussi connu sous le nom d'équations de Lotka-Volterra. Il décrit, sous la forme d'équations, la dynamique de systèmes biologiques où deux entités interagissent : un prédateur et sa proie. Le modèle multi-agent qui s'en inspire modélise les entités de ce système sous la forme d'agents qui évoluent dans un environnement. Dans notre modèle, cet environnement est discrétisé en une grille de cellules en deux dimensions. Les prédateurs, tout comme les proies, y sont placés aléatoirement. Tous les prédateurs possèdent un champ de vision (<i>Field Of View</i>, FOV) de dix cellules autour d'eux. Si une proie se trouve dans leur FOV, ils la ciblent et se dirigent vers elle, sinon ils se déplacent aléatoirement. Les proies se déplacent aussi de manière aléatoire. Lorsqu'un prédateur se trouve dans le FOV d'une proie (qui est de six cellules autour d'elle), cette dernière tente de s'échapper en s'enfuyant dans la direction opposée. Une proie meurt quand elle est ciblée par un prédateur et quand ce dernier se trouve sur la même case.</p>

            <p><b>Application de la méthode</b></p>

            <p><b>Étape 1.</b> : comme précédemment, on commence par décomposer les différents calculs présents.</p>
            <ul>
            <li><p>L'environnement est statique et ne possède aucune dynamique environnementale.</p></li>
            <li><p>Pour les agents : Les prédateurs (C1) déterminent la direction vers la proie la plus proche et (C2) se déplacent. Les proies (C3) calculent leur direction de fuite face aux prédateurs et (C4) se déplacent.</p></li>
            </ul>

            <div class="portfolio-page-image">
                <img src="./these/images_chap6/preypredator.svg" alt=""/>
            </div>

            <p><b>Étape 2.</b> : parmi ces 4 calculs présents dans le modèle, on identifie maintenant ceux qui sont compatibles avec les critères du principe de délégation GPU. C2 et C4 consistent en des déplacements modifiant de ce fait les états des agents (leur position). Ainsi, on ne les considère pas pour la suite car ces derniers ne respectent pas les critères d'éligibilité du principe de délégation GPU. C1 et C3, quant à eux, consistent à calculer la direction de fuite des proies face aux prédateurs (C1) et la direction vers la proie ciblée pour les prédateurs (C3). Ces deux calculs, à l'origine réalisés dans les comportements des agents (création d'une liste des voisins, parcours de la liste, calcul des directions), peuvent être pensés comme une perception pré-calculée par une dynamique environnementale. Dans ce cas, cette dynamique calculera pour chaque cellule de l'environnement les directions vers les proies et les prédateurs les plus proches mais aussi les directions opposées. Les agents n'auront plus qu'à percevoir en fonction de leur type la direction qui les intéresse et agir en conséquence. La transformation de ces calculs en dynamiques environnementales traitées par un module GPU est possible car ces modules ne modifient pas les états des agents.</p>

            <p><b>Étape 3.</b> : C1 et C3 sont identifiés comme compatibles avec le principe de délégation GPU. Pour ces calculs, il est possible de réutiliser le module <i>GPU field perception</i> créé pour le modèle MLE. En effet, ce module calcule pour chaque cellule la direction vers des cellules voisines possédant la plus grande/faible quantité d'une variable donnée. Ici, cette variable correspond à la présence ou non d'agents dans le voisinage et peut donc être considérée comme un gradient de présence du voisinage. Ce gradient de présence calcule ainsi les directions maximales et minimales vers les agents les plus proches. Il est cependant essentiel d'adapter correctement les structures de données envoyées au module GPU.</p>

            <p><b>Étape 4.</b> : du fait que l'on réutilise un module déjà existant et qu'aucun nouveau calcul n'a été identifié comme compatible, il est possible de passer directement à l'étape 5.</p>

            <p><b>Étape 5.</b> : suite aux 4 étapes précédentes, on peut appliquer le principe de délégation GPU sur C1 et C3 qui remplissent toutes les exigences requises.</p>

            <p>Pour implémenter le module dédié à C3, un tableau à une dimension est utilisé (<i>preyMark</i>) contenant une marque de présence déposée par chaque proie à chaque pas de temps de la simulation. Plus le nombre de proies va être important à un endroit précis de l'environnement et plus la marque de présence sera importante. Ce tableau est ensuite envoyé au module <i>GPU field perception</i> qui va tester le voisinage proche de chaque cellule de l'environnement et déterminer la direction menant à la marque de présence des proies la plus forte. Plus précisément, cette vérification va consister à prendre une cellule voisine de la cellule considérée, récupérer sa valeur de présence, tester si cette valeur récupérée est plus grande que la valeur en mémoire. Ensuite, l'index de la case ayant la plus forte marque de présence est utilisé pour calculer l'angle vers cette case. Le résultat est ensuite écrit dans un nouveau tableau (<i>preyMaxDirection</i>). Ainsi, les prédateurs n'ont plus qu'à percevoir, en fonction de leur position, dans le tableau <i>preyMaxDirection</i> la valeur d'orientation correspondant à la direction vers la proie la plus proche.</p>

<pre>
i = blockIdx.x * blockDim.x + threadIdx.x;
j = blockIdx.y * blockDim.y + threadIdx.y;
float max = 0;
int maxIndex = 0;

Si(i &lt; width et j &lt; height){
    Pour(int u = 1 ; u &lt; 8; u++){

    float current = getNeighborsValues(u, preyMark[convert1D(i,j)]);

    Si(max &lt; current){
        max = current;
        maxIndex = u;
    }
}
preyMaxDirection[convert1D(i,j)] = maxIndex * 45;
</pre>

            <p>Pour C1, le calcul est similaire, ce qui permet d'utiliser une nouvelle instance de ce module. Un tableau contenant les marques de présence des prédateurs est donc envoyé au module GPU et un tableau résultat contenant les directions vers les prédateurs est retourné. Cependant, les proies ne cherchent pas la direction vers les prédateurs mais la direction opposée. Ainsi, et pour ne pas modifier le module utilisée précédemment, chaque direction pointant vers les prédateurs se voit ajouter 180 degrés. De ce fait, ces directions représentent maintenant des directions de fuite face aux prédateurs. A la suite de ce calcul, les proies n'ont plus qu'à percevoir, en fonction de leur position, dans le tableau résultat la valeur d'orientation correspondant à la direction de fuite face aux prédateurs les plus proches.</p>

<pre>
Tantque(simu){
/*Activation des agents*/
    Pour(agent dans listOfAgents){
        live();
        Si(agent == prey){
            fillMarkArray(preyMark[]);
        }
        Si(agent == predator){
            fillMarkArray(predatorMark[]);
        }
    }

    /*Activation de l'environnement*/
    executeGPUKernel( GPUFieldPerception(preyMark[]) );
    executeGPUKernel( GPUFieldPerception(predatorMark[]) );
}
</pre>


            <p><b>Performance du modèle</b></p>
            
            <p>Pour tester les performances du modèle Proie-prédateur, nous avons simulé successivement les versions CPU et hybride pour des environnements de taille 256, 512, 1 024 et 2 048. Pour chacune de ces tailles d'environnement, nous avons fixé la densité des agents à 20 % puis à 40 %. La répartition entre proies et prédateurs est la suivante : 90 % de proies et 10 % de prédateurs.</p>

            <div id="chart_chap6_2" class="chart"></div>

            <p>Des graphiques, on observe une nouvelle fois que la différence de performance entre les deux versions du modèle est d'autant plus importante que l'environnement est grand. De plus, on note que l'augmentation de la densité des agents accélère cette différence.</p>

            <br/>
            <div class="block-title">
                <h3>Avantages et limites de la méthode proposée</h3>
            </div>

            <h4>Du point de vue des performances</h4>

            <p>Tout comme pour les expérimentions précédentes, l'application de la méthode sur les modèles <i>Heatbugs</i> et Proie-prédateur permet d'obtenir une amélioration des temps d'exécution comparé à une exécution séquentielle des modèles. La recherche de performance n'étant pas l'unique objectif de cette méthode, il faut noter que l'accélération obtenue (jusqu'à 4 fois plus rapide) est tout de même significative et ouvre des possibilités importantes vis-à-vis de la scalabilité des modèles simulés.</p>

            <div id="chart_chap6_3" class="chart"></div>

            <p>Cependant, on retrouve une des limites déjà rencontrée au chapitre précédent : les résultats de performance varient énormément en fonction du modèle considéré. En effet, alors que le gain de performance pour le modèle Proie-prédateur atteint 4.5, celui du modèle <i>Heatbugs</i> n'excède pas 1,1. Ainsi, même si le modèle considéré est compatible avec les critères du principe de délégation GPU et rempli les exigeances des 5 étapes de la méthode, il est possible d'obtenir de faibles gains de performance. Dans le cas du modèle <i>Heatbugs</i>, ces résultats s'expliquent par la part du modèle qui utilise le GPGPU. En effet, seul un faible pourcentage des calculs bénéficient du calcul sur carte graphique. Ainsi, les calculs qui continuent d'utiliser le CPU brident les performances globales du modèle.</p>

            <p>Plus généralement, ce bridage des performances peut aussi venir du fait que le modèle considéré ne contient aucunes dynamiques environnementales. Ces dernières étant les plus facilement parallélisables, elles offrent généralement de très gros gains de performance une fois traitées par un module GPU. De plus, lorsque dans le modèle seuls des calculs de perceptions peuvent être transformés, les performances du modèle deviennent alors très dépendantes du nombre d'agents présents : si ce nombre est faible, le gain peut être négatif. Les performances vont donc dépendre des caractéristiques du modèle considéré.</p>

            <p>De plus, les gains de performance vont aussi varier en fonction du type (professionnel ou grand public) et du nombre de GPU. Le fait d'avoir utilisé, pour nos expérimentations, qu'une seule carte graphique a certainement impacté la qualité des résultats obtenus. En effet, vu que cette dernière doit aussi gérer l'affichage du système d'exploitation et de la simulation, ses ressources dédiées aux calculs GPGPU en sont d'autant diminuées présente une solution pour améliorer les performances de rendu de TurtleKit qui utilise le moteur OpenGL lorsque l'ordinateur utilisé ne contient qu'une seule carte graphique. Ainsi, les performances du modèle vont aussi fortement dépendre de la configuration matérielle utilisée.</p>

            <p>Nous pensons donc qu'une évaluation des performances escomptées doit être réalisée au préalable de toute application afin de ne pas perdre de temps dans des développements qui n'apporteraient aucun bénéfice en termes de performance. Actuellement, cela représente une limite pour notre méthode qui à ce stade ne définit pas le niveau d'accélération qu'il va être possible d'obtenir. Considérant cette limite.</p>

            <h4>Du point de vue conceptuel</h4>
            
            <p>Tous les cas d'étude et expérimentations menés jusqu'ici soulignent la polyvalence dont fait preuve notre approche dans le sens où elle peut être appliquée sur une grande variété de modèles : MLE, les <i>boids</i> de Reynolds, <i>Game Of Life</i>, <i>Schelling's Segregation</i>, <i>DLA</i>, <i>Fire</i>, <i>Heatbugs</i> et enfin Proie-prédateur.</p>

            <p>Un autre avantage de notre méthode est son accessibilité. En effet, il a été très facile, en suivant la méthode, d'identifier des parties des différents modèles qui ont pu être transformées pour bénéficier du GPGPU. Les 5 étapes amènent l'utilisateur à identifier les parties compatibles et à créer le ou les modules GPU correspondants aux calculs éligibles. De plus, les modules GPU possèdent toujours la même structure se basant sur des <i>kernels</i> très simples à écrire comportant seulement quelques lignes de codes (très similaire au langage C).</p>

            <p>D'ailleurs, cette méthode produit des modules génériques et donc réutilisables dans d'autres contextes que ceux pour lesquels ils ont été créés. Cette réutilisabilité a été illustrée de nombreuses fois pendant nos expérimentations et dernièrement par le modèle Proie-prédateur avec la réutilisation du module <i>GPU field perception</i> initialement créé pour le modèle MLE.</p>

            <p>Enfin, nous avons vu que le principe de délégation GPU suit la perspective qui vise à déplacer une partie de la complexité des agents vers l'environnement afin de mieux la gérer. Cette perspective est clairement visible dans le dernier modèle sur lequel la méthode a été appliquée : pour Proie-prédateur, l'application de la méthode a transformé tous les calculs annexes aux comportements des agents permettant de ce fait d'avoir un modèle (et donc un code source) très lisible et facilement compréhensible. Nous rediscutons d'ailleurs de cet aspect au chapitre suivant.</p>

            <br/>
            <div class="block-title">
                <h3>Résumé du chapitre</h3>
            </div>

            <p>Comme point final à ce travail, nous avons considéré de formaliser dans ce chapitre le principe de délégation GPU expérimenté tout au long de ce manuscrit. Ainsi, une méthode de conception divisée en 5 étapes a été proposée. Avec comme objectif de définir un cadre pour l'implémentation de simulations multi-agents sur le GPU, cette méthode se devait également de prendre en considération des aspects tels que la <i>généricité</i>, l'<i>accessibilité</i> et la <i>réutilisabilité</i> (nos trois critères d'évaluation). L'expérimentation réalisée par la suite sur deux nouveaux modèles multi-agents a montré que cette méthode prenait en compte ces critères tout en offrant des gains de performance significatifs.</p>

            <p>A la vue de tous ces résultats, il convient de conclure ce travail et de discuter de l'impact que peut avoir une telle méthode sur le développement de simulations multi-agents. C'est ce que nous proposons maintenant de faire au chapitre suivant.</p>

            <div class="ajax-page-nav">
                <div class="nav-item ajax-page-prev-next">
                    <a class="ajax-page-load" href="./these/t_chap5.html"><i class="pe-7s-icon pe-7s-angle-left"></i></a>
                    <a class="ajax-page-load" href="./these/t_chap7.html"><i class="pe-7s-icon pe-7s-angle-right"></i></a>
                </div>
                <div class="nav-item ajax-page-close-button">
                    <a id="ajax-page-close-button" href="#"><i class="pe-7s-icon pe-7s-close"></i></a>
                </div>
            </div>            

            <script type="text/javascript">
                function customAjaxScroll() {
                        var windowWidth = $(window).width();
                        if (windowWidth > 991) {
                            // Custom Ajax Page Scroll
                            $("#ajax-page").mCustomScrollbar({
                                scrollInertia: 8,
                                documentTouchScroll: false
                            });
                        } else {
                            $("#ajax-page").mCustomScrollbar('destroy');
                        }
                    }

                    jQuery(document).ready(function($){

                        // Ajax Loaded Page Scroll
                        customAjaxScroll();

                        Highcharts.chart('chart_chap6_1', {
                            chart: {
                                type: 'line'
                            },
                            title: {
                                text: 'Heatbugs, gains entre la version CPU et hybride'
                            },
                            xAxis: {
                                title: {
                                    text: 'Taille environnement'
                                },
                                categories: ['256', '512', '1024', '2048']
                            },
                            yAxis: {
                                title: {
                                    text: 'Gains de performance'
                                }
                            },
                            series: [{
                                name: 'Comportement des agents',
                                data: [0.9090, 0.9780, 1.0229, 1.0435]
                            },{
                                name: 'Dynamiques environnementales',
                                data: [1, 2, 2.625, 7.5294]
                            }]
                        });

                        Highcharts.chart('chart_chap6_2', {
                            chart: {
                                type: 'line'
                            },
                            title: {
                                text: 'Modèle Proie-prédateur, résultats de performance'
                            },
                            xAxis: {
                                title: {
                                    text: 'Taille environnement'
                                },
                                categories: ['0','256', '512', '1024', '2048']
                            },
                            yAxis: {
                                title: {
                                    text: 'Temps de calcul par itération [ms]'
                                }
                            },
                            series: [{
                                name: 'CPU',
                                data: [26, 118, 576, 4402]
                            },{
                                name: 'Hybride',
                                data: [13, 51, 231, 1075]
                            }]
                        });

                        Highcharts.chart('chart_chap6_3', {
                            chart: {
                                type: 'line'
                            },
                            title: {
                                text: 'Gains de performance entre les versions CPU et hybride des différents modèles'
                            },
                            xAxis: {
                                title: {
                                    text: 'Taille environnement'
                                },
                                categories: ['256', '512', '1024', '2048']
                            },
                            yAxis: {
                                title: {
                                    text: 'Gains de performance'
                                }
                            },
                            series: [{
                                name: 'Heatbugs',
                                data: [1.04, 1.06, 1.08, 1.10]
                            },{
                                name: 'Proie-prédateur',
                                data: [2, 2.1, 2.5, 4.5]
                            }]
                        });

                        $('.portfolio-page-carousel').owlCarousel({
                            smartSpeed:1200,
                            items: 1,
                            loop: true,
                            dots: true,
                            nav: true,
                            navText: false,
                            margin: 10
                        });

                    });

                    jQuery(window).on('resize', function() {
                        customAjaxScroll();
                    });

            </script>
        </div>
    </div>
</div>

<div id="ajax-page" class="ajax-page-content">
    <div class="ajax-page-wrapper">
        <div class="ajax-page-nav">
            <div class="nav-item ajax-page-prev-next">
                <a class="ajax-page-load" href="./these/t_chap2.html"><i class="pe-7s-icon pe-7s-angle-left"></i></a>
                <a class="ajax-page-load" href="./these/t_chap4.html"><i class="pe-7s-icon pe-7s-angle-right"></i></a>
            </div>
            <div class="nav-item ajax-page-close-button">
                <a id="ajax-page-close-button" href="#"><i class="pe-7s-icon pe-7s-close"></i></a>
            </div>
        </div>

        <div class="ajax-page-title">
            <div class="chapter-title"><h2>Chapitre 3 : Simulations multi-agents et GPGPU</h2></div>
        </div>

        <div class="row">
            <br/>
            <div class="col-sm-6 col-md-6 subpage-block">
                <ul class="project-general-info">
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap1.html"> Chapitre 1 : Simulation multi-agent</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap2.html"> Chapitre 2 : Calcul haute performance et GPGPU</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap4.html"> Chapitre 4 : Le principe de délégation GPU des perceptions agents</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap5.html"> Chapitre 5 : Expérimentation du principe de délégation GPU</a></p></li>
                </ul>
            </div>
            <div class="col-sm-6 col-md-6 subpage-block">
                <ul class="project-general-info">
                    
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap6.html"> Chapitre 6 : Définition d'une méthode de conception basée sur la délégation GPU</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap7.html"> Chapitre 7 : Conclusion</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_chap8.html"> Chapitre 8 : Perspectives de recherche</a></p></li>
                    <li><p><i class="fa fa-globe"></i> <a class="ajax-page-load" href="./these/t_bib.html"> Bibliographie</a></p></li>
                </ul>                
            </div>

            <p>Le temps d'exécution d’une simulation multi-agent est une contrainte importante qui préfigure de notre capacité à explorer et étudier le modèle simulé. Ainsi, plutôt que de devoir le simplifier et/ou faire des compromis (jouer sur la scalabilité du modèle et/ou sur sa visualisation), utiliser le GPGPU, afin d’améliorer les performances des simulations et ainsi lever une partie des contraintes liées au passage à l’échelle, peut être une piste de recherche intéressante [Che2008].</p>

            <p>Cependant, le GPGPU repose sur l'utilisation d'une architecture matérielle spécifique, hautement parallèle, nécessitant une programmation particulière [Bourgoin2013-2] qui va forcément avoir une incidence sur la mise en oeuvre des modèles multi-agents. Nous proposons donc, dans ce contexte, de réaliser un état de l'art sur l'utilisation du GPGPU dans le cadre de la simulation multi-agent [Hermellin-JFSMA-2014, Hermellin-RIA-2015] afin de souligner dans quelle mesure les spécificités de cette technologie vont impacter la modélisation et l'implémentation des simulations multi-agents sur GPU.</p>

            <p>Cette question est d'autant plus pertinente que très peu des plates-formes de développement spécialisées dans la simulation multi-agent n'intègrent, en leur sein, de fonctionnalités dédiées au GPGPU ou plus généralement au calcul intensif. NetLogo [Sklar2007] conserve une implémentation séquentielle classique alors que RePast [Repast2007] intègre le calcul intensif via une utilisation des clusters de CPU [RepastHPC]. Seul MasOn [Luke2005] propose une intégration du GPGPU (avec même une possibilité d'utiliser plusieurs GPU [Ho2015]).</p>

            <p>Ainsi, nous constaterons que les travaux mêlant GPGPU et simulations multi-agents sont majoritairement liés à des expérimentations très particulières limitant leur réutilisation. D'ailleurs, ces questions autour de la facilité de programmation et de l'accessibilité à cette technologie sont courantes dans le domaine du HPC et ne sont pas seulement propre au GPGPU. En effet, même une parallélisation d'une simulation sur CPU pose des problèmes comme le montre [Axtell2016].</p> 

            <p>Pour figurer dans l'état de l'art, que nous proposons dans ce chapitre, chacune des contributions sélectionnées devra répondre aux critères suivants :</p> 
            <ul>
            <li><p>Les contributions doivent traiter de l'utilisation du GPGPU dans un contexte multi-agent ;</p></li>
            <li><p>Les travaux sélectionnés doivent soit introduire de nouveaux outils, frameworks, bibliothèques dédiées, soit présenter des études, méthodologies ou <i>benchmarks</i> relatifs à l'utilisation du GPGPU dans le contexte multi-agent.</p></li>
            </ul>

            <p>Dans le cas ou plusieurs contributions discutent du même aspect, ou présentent un même outil, nous sélectionnons celui qui est le plus complet afin d'éviter toute redondance. Nous tenons à noter que cet état de l'art ne se veut pas exhaustif, son objectif premier est de donner un aperçu de ce qu'il se fait et est possible de faire avec le GPGPU dans la communauté multi-agent.</p>

            <p>La présentation des différentes contributions sélectionnées est faite en fonction des choix d'implémentations et des techniques utilisées. En effet, implémenter une simulation multi-agent sur GPU peut se faire de deux manières distinctes, chacune possédant des avantages et inconvénients. La première consiste à exécuter entièrement la simulation sur le GPU, nous la nommons <i>tout-sur-GPU</i>. La seconde partage l'exécution de la simulation entre le CPU et le GPU et est classiquement qualifiée d'<i>hybride</i>. Nous choisissons de suivre cette distinction afin de classer les contributions sélectionnées.</p>

            <br/>
            <div class="block-title">
                <h3>Implémentation tout-sur-GPU</h3>
            </div>

            <p>Historiquement, l'implémentation d'une simulation multi-agent entièrement sur GPU se faisait via l'utilisation et le détournement des fonctions graphiques du GPU, du fait du manque d'API dédiées. Par la suite, des API spécialisées dans le GPGPU, telles que CUDA et OpenCL, ont été créées et ont eu comme objectif de rendre accessible l'utilisation de cette technologie. Les détails techniques d’implémentation associés à ces deux méthodes d'utilisation du GPGPU ont été énoncés dans le chapitre précédent et sont explicités dans [Owens2007].</p>
            
            <div class="portfolio-page-image">
                <img src="./these/images_chap3/AllInGPU.svg" alt=""/>
            </div>

            <h4>Utilisation des fonctions graphiques des GPU</h4>
            
            <p><i>SugarScape</i> est le premier SMA ayant profité d'un portage sur GPU [D'Souza2007]. C'est un modèle multi-agent très simple dans lequel des agents réactifs évoluent dans un environnement discrétisé en cellules contenant une ressource, le sucre, et suivent des règles comportementales basiques (déplacement, reproduction, etc.). Avec cette implémentation, la simulation <i>SugarScape</i> permettait de voir évoluer en temps réel plus de 2 millions d'agents dans un environnement d'une résolution de 2 560 par 1 024. La performance était d'autant plus encourageante qu'elle a été réalisée à l'aide d'un ordinateur grand public équipé d'une carte graphique comportant seulement 128 coeurs. D'un point de vue performance, cette adaptation GPU surpassait ainsi toutes les versions séquentielles de SugarScape tout en permettant d'avoir une population d'agents encore jamais vue dans des environnements plus larges.</p>

            <p>Lysenko et D'Souza, motivés par ces très bons résultats, se sont ensuite attaqués au problème de l'accessibilité en généralisant leur approche et en proposant un framework destiné à faciliter l'implémentation de modèle sur GPU [Lysenko2008]. Celui-ci était composé de fonctions de bases telles que la gestion de données environnementales, la gestion des interactions entre agents, des fonctions pour la naissance et mort des agents, etc. Cependant, il ne permettait que des implémentations de modèles similaires à <i>SugarScape</i> comportant uniquement des agents réactifs aux comportements peu évolués du fait de la difficulté d'implémenter des architectures agents complexes sur GPU.</p>

            <p>Suivant cette tendance, et dans le but de simplifier encore plus l'utilisation du GPGPU, le framework ABGPU se proposait d'être une interface de programmation un peu plus générique (similaire à celle que l'on pouvait trouver sur CPU) et surtout plus accessible grâce à une utilisation transparente du GPU reposant sur un ensemble de classes C/C++ et un système de mots clés [RichmondDaniela2008]. À cela s'ajoutaient des fonctions et des classes pré-programmées, facilitant d'avantage l'implémentation de comportements et fonctions agents un peu plus évoluées (fonctions de synchronisations, communications, etc). ABGPU se voulait optimisé pour des simulations dans lesquelles évoluaient des agents réactifs aux comportements simples (<i>e.g.</i> simulations de <i>flocking</i>). ABGPU était ainsi capable de simuler et d'afficher 65 536 agents en mouvements et en interactions en temps réel et en 3D en utilisant une carte graphique composée de 112 coeurs.</p>

            <p>Cependant, même dans le cas d'architectures agents très simples, ces travaux pionniers soulignent la difficulté de mettre en place une méthode de conversion générique pour le portage de simulations multi-agents sur GPU, notamment du fait de la grande diversité des modèles. À ce propos, [Perumalla2008] a étudié les contraintes associées à de telles conversions en réalisant l'implémentation de différents modèles (<i>Mood Diffusion</i>, <i>Game of Life</i> et <i>Schelling Segregation</i>) sur CPU (avec <i>NetLogo</i> [Sklar2007] et <i>Repast</i> [Repast2007]), puis sur GPU. Ces cas d'études montrent bien que les spécificités de la programmation sur GPU rendent difficile, voire impossible, le processus de conversion qui est bien plus complexe qu'un simple changement de langage de programmation. En effet, avec le GPGPU, de nombreux concepts présents en programmation séquentielle ne sont plus disponibles. Du fait de ces difficultés, le besoin en outils et interfaces spécialisés était très grand et leur apparition va permettre une expansion du GPGPU.</p>

            <h4>Utilisation des API dédiées au GPGPU</h4>

            <p>Avec l'arrivée de CUDA et OpenCL, l'utilisation du GPGPU a été grandement simplifiée et celui-ci est devenu une solution incontournable dans de nombreux domaines où le temps de calcul est critique (comme illustré par [Zhang2011] avec un modèle multi-level permettant la visualisation de la progression d'une tumeur cérébrale). Ainsi, le nombre de travaux utilisant le GPGPU a pu augmenter et de nouveaux outils et frameworks ont vu le jour.</p>

            <p>Le plus représentatif est Flame GPU [Richmond2010]. En effet, Flame GPU est une solution clef en main pour la création de simulations multi-agents sur GPU et possède plusieurs avantages. Tout d'abord, Flame GPU se focalise sur l'accessibilité en s'appuyant sur une utilisation transparente du GPGPU. Pour cela, il utilise les X-machines [Coakley2006] : un formalisme de représentation d'agents s'appuyant sur une extension du langage XML : le XMML. Ainsi, les données initiales de la simulation ainsi que les états des agents sont implémentés dans des fichiers XMML pendant que les comportements de ces derniers sont programmés en C. Les fichiers XMML vont être combinés dans des templates GPUXMML et ensuite vérifiés par un processeur XSLT dans le but d'être compilés dans le langage GPU avec les fichiers de comportements en C. La simulation est ensuite générée puis exécutée par le GPU.</p>

            <div class="portfolio-page-image">
                <img src="./these/images_chap3/FlameGPU.svg" alt=""/>
            </div>

            <p>De plus, Flame GPU fournit un framework open source contenant des modèles agents pré-programmés facilement réutilisables. Ainsi, il devient le premier framework capable de simuler un large éventail de modèles dans des contextes et domaines différents : en biologie (<i>e.g.</i> simulation de cellules de peau [Richmond2009a]), en intelligence artificielle (<i>e.g.</i> simulation proie - prédateur [Richmond2009b]), ou pour des simulations de foules (<i>e.g.</i> [Karmakharm2010, Karmakharm2012]).</p>

            <p>Dernièrement, Flame GPU a évolué et se base maintenant sur l'architecture Flame II [Coakley2016]. Cette nouvelle version met encore plus l'accent sur la généricité et intègre (pour la version GPU) un nouveau découpage des actions des agents (les comportements des agents sont décomposés) permettant une limitation des accès concurrents aux données et une meilleure gestion de la mémoire, ce qui augmente la performance générale du modèle.</p>

            <p>Cependant, bien que les avancées apportées par Flame GPU en termes d'accessibilité et de généricité soient remarquables, la solution proposée par ce framework nécessite d'adhérer à une modélisation peu intuitive basée sur XML. De plus, les abstractions utilisées pour cacher la complexité du GPGPU réduisent naturellement les performances. C'est pourquoi, comme nous allons le voir maintenant, beaucoup de travaux existants partent de zéro et se focalisent uniquement sur les gains de performances. Cela est particulièrement vrai dans le cadre de travaux portant sur l'étude de modèles de <i>flocking</i>, de foules ou de simulations de trafic.</p>

            <p><b>Les simulations de <i>flocking</i></b>
            Le modèle de <i>flocking</i> de Reynolds [Reynolds1987] fait partie des simulations multi-agents les plus connues. C'est un modèle multi-agent qui permet de réaliser des animations réalistes de nuées d'oiseaux artificiels (<i>boids</i>) grâce à une approche individu-centrée. En effet, dans ce modèle, chaque entité est considérée comme un agent unique possédant des règles de comportements et d'interactions. Ces agents peuvent ainsi reproduire de manière expérimentale des comportements de groupes et de modèles biologiques réalistes (<i>cf.</i> IBM, de l'anglais <i>Individual Based Model</i> [Michel2009]).</p>

            <p>Motivé par la possibilité de simuler un très grand nombre d'agents (jusqu'à plusieurs millions), des simulations de <i>flocking</i> ont été portées sur GPU dans le but de profiter des performances de ces cartes. Ainsi, plusieurs contributions significatives ont vu le jour. On peut notamment citer [Passos2008] qui introduit la première simulation de <i>flocking</i> sur GPU ou encore [Li2009] qui ajoute la notion d'évitement d'obstacles dans son modèle.</p>

            <p>Le travail présenté dans [Erra2009] est aussi très intéressant car il propose une description complète et détaillée des étapes suivies pour implémenter un modèle sur GPU en utilisant l'API de Nvidia. Reprenant les bases énoncées dans les travaux de Reynolds, les agents de ce modèle ne vont avoir qu'une représentation locale de leur environnement et se coordonnent avec leurs plus proches voisins. Ce travail offre une vision globale de la faisabilité et des performances que l'on peut obtenir en utilisant le GPGPU pour des modèles de <i>flocking</i>. Dans ces simulations, des millions d'individus sont rendus à l'écran en temps réel et en 3D par une carte graphique comportant 128 coeurs.</p>

            <p>Dans le but d'accélérer le calcul des simulations de <i>flocking</i> et pour en améliorer le rendu graphique, [Silva2009] propose un nouveau modèle intégrant une technique de <i>self-occlusion</i>. L'idée proposée est que chaque agent est plus ou moins visible en fonction de sa distance avec l'agent sur lequel on se focalise. De plus, [Silva2009] présente aussi une comparaison entre deux implémentations de son travail : l'une utilisant directement les fonctions graphiques de la carte et l'autre basée sur CUDA. Les résultats obtenus montrent que, même dans le cas de CUDA, abstraire la couche matérielle ne peut se faire qu'au détriment des performances : le même modèle utilisant directement les fonctions graphiques du GPU reste plus rapide.</p>

            <p>Finalement, [Husselmann2011] propose un modèle de <i>flocking</i> sur GPU plus complexe capable de simuler un environnement comportant plusieurs espèces d'entités différentes (hétérogénéité des agents). De plus, il est possible de donner à chaque type d'agents une personnalité différente caractérisée par des paramètres spécifiques à l'agent. L'étude de ce système est rendue possible grâce à la puissance de calcul offerte par le GPGPU et va ainsi permettre de voir apparaître des comportements émergents entre agents hétérogènes (<i>flock separation behaviour</i>) et donc d'avoir des modèles de <i>flocking</i> plus complexes. L'implémentation de ce modèle a été testée sur 5 cartes graphiques différentes (comportant de 192 coeurs jusqu'à 512 coeurs) et les résultats montrent un temps de calcul et de rendu 3D par image entre 0,08 secondes et 0,14 secondes pour environ 37 000 entités simulées.</p>

            <p><b>Les simulations de foule et de trafics</b>
            Les simulations de foules font aussi partie des domaines pour lesquels il est pertinent d'étudier des environnements et des populations d'agents toujours plus grands. Dans ce cas, et comme pour le <i>flocking</i>, l'utilisation du GPGPU devient pertinente.</p>

            <p>Évolution du framework ABGPU, le <i>Pedestrian framework</i> [Richmond2011], basé sur CUDA, ne se focalise pas seulement sur la performance. En effet, il propose de modéliser pour la première fois des agents ayant un comportement cognitif tels que ceux décrits dans [Romano2005]. Qualifiés de sociaux, ces agents s'adaptent à leur environnement et s'expriment au travers de leurs actions et gestes. Ce framework permet aussi d'intégrer dans la simulation des forces sociales et en particulier celles énoncées par Helbing [Helbing2002]. Pour cela, [Richmond2011] propose de distinguer explicitement agent et environnement, ce dernier étant chargé de représenter des forces environnementales virtuelles qui attirent les agents vers des points d'intérêt (vitrines de magasins, événements spéciaux, etc.). En utilisant ce framework, il est possible de simuler 65 536 agents en 3D et en temps réel avec une carte graphique contenant seulement 96 coeurs.</p>

            <p>[Varga2014] présente un modèle de simulation de mouvement d'agents pédestres évoluant dans un environnement discrétisé en cellules. Les agents ne vont avoir qu'une perception locale de leur environnement mais vont posséder un espace local autour d'eux. Cet espace local est lui aussi divisé en cellules, chacune caractérisée par un état et une valeur. L'état de la cellule peut être "libre" ou "bloquée", la valeur correspond à l'opportunité de se déplacer dans cette cellule. Cette valeur est calculée en fonction des champs de gradients diffusés par les objectifs à atteindre, les objets de l'environnement, les autres agents, les obstacles, etc. Ce calcul peut être effectué de manière indépendante sur chaque cellule ce qui rend la parallélisation et l'utilisation du GPGPU très effectif. L'agent va ainsi se déplacer de cellule en cellule vers son but en s'adaptant à ce qui se passe dans l'environnement.</p>

            <p>Dans [Chen2015], un framework de simulation dédié aux scénarios d'évacuation a été développé. Chaque individu est modélisé comme un agent dirigé par un mécanisme de prise de décision (chacune des décisions étant en plus pondérée par un poids) offrant, au final, la possibilité de mieux comprendre les interactions entre individus, entre groupes ou encore entre individus et environnement. Ce travail propose aussi un schéma innovant permettant de réduire la surcharge provoquée par un accès trop important aux différents paramètres globaux du système par tous les agents. Pour toutes les expérimentations menées, une carte Nvidia GTX 580 (possédant 512 coeurs CUDA) a été utilisée, ce qui a permis de simuler l'évacuation du Stade National de Beijing contenant pas moins de 90 000 agents. Ces tests représentent un bon exemple de ce que peut apporter le GPGPU, l'implémentation utilisant CUDA ayant été 38 fois plus rapide que l'implémentation séquentielle correspondante.</p>

            <p>Assez similaire aux simulations de foules et d'évacuation, il existe des recherches portant sur des modèles simulant des réseaux routiers dans des environnements plus ou moins dynamiques. Les motivations qui poussent à la réalisation de ces outils sont l'amélioration de la sécurité et l'évitement des congestions des réseaux de circulation. En effet, ces simulations vont permettre de prendre des décisions et améliorer les évacuations en cas de situation d'urgence. Nécessitant aussi une grande puissance de calcul, les gains de performances offerts par le GPGPU sont clairement visibles dans [Strippgen2009] et [Shen2011].</p>

            <p>Cependant, la simulation de trafic à grande échelle est une tâche difficile car elle nécessite de prendre en compte différents niveaux au sein du même modèle. En effet, il peut être intéressant de faire cohabiter ensemble des modèles microscopiques, pour les sections urbaines, et des modèles macroscopiques, pour les zones d'autoroutes permettant de ce fait d'améliorer le réalisme des modèles simulés. C'est ce que propose de faire JAM-FREE [Abouaissa2015], un framework multi-agent dédié à la simulation de trafic possédant plusieurs niveaux de représentation. Basé sur SIMILAR (<i>SImulations with MultI-Level Agents and Reactions</i>), JAM-FREE permet de simuler des réseaux de trafic de grande taille efficacement en adaptant dynamiquement le niveau de détails tout en testant de nouveaux algorithmes de régulation, d'observation, de routage, etc. Son moteur de simulation étant considéré comme une abstraction de haut niveau, il met à la disposition des utilisateurs les outils et fonctions nécessaires à l'utilisation d'architectures parallèles (tels que les GPU) pour simuler les modèles.</p>

            <p><b>Les algorithmes de navigation</b>
            Avec le nombre important de travaux exploitant le GPGPU dans le domaine des simulations de foules ou de trafics, la question de la réutilisation et de la généralisation s'est posée. Dans le même temps, les systèmes multi-agents ont gagné en popularité auprès des développeurs de jeux vidéo et surtout pour le développement d'intelligences artificielles. Dans ce cadre, la navigation autonome et la planification d'itinéraires ont été rapidement identifiées comme des fonctions couramment utilisées. Ainsi, les travaux que nous allons voir maintenant proposent des implémentations d'algorithmes permettant de résoudre le problème de <i>Pathfinding</i> et <i>Pathplanning</i> dans un contexte agent sur GPU. De par leur aspect distribué, ces algorithmes s'adaptent très bien aux architectures massivement parallèles et de très gros gains de performances peuvent être obtenus.</p>

            <p>[Bleiweiss2008] est le premier à proposer une implémentation de l'algorithmes de Dijkstra et A* sur GPU. Ceux-ci seront ensuite modifiés dans [Caggianese2012] afin de s'adapter en temps réel tout au long de la simulation. [DosSantos2012] apporte aussi une contribution en proposant une nouvelle standardisation pour l'utilisation des GPU dans un contexte agent en respectant le standard FIPA (de l'anglais <i>Foundation for Intelligent Physical Agents</i>) afin de rendre possible la modélisation de comportements plus complexes. Pour tester cette approche, un cas d'étude a été implémenté : celui-ci consiste en une simulation de foule dans laquelle les agents utilisent l'algorithme A* pour trouver leur chemin.</p>

            <p>Cependant, ces algorithmes fonctionnent en ayant une représentation globale de l'environnement et sont connus pour donner des comportements peu réalistes. Pour considérer ce problème, des algorithmes centrés sur l'agent et basés sur des perceptions locales ont été proposés dans le cadre du GPGPU. On peut citer par exemple l'algorithme BVP Planner [Fischer2009] qui utilise une carte globale couplée à des cartes locales gérées par les agents. Ces cartes locales contiennent des buts intermédiaires, générés en fonction des perceptions de l'agent, lui permettant ainsi de réagir de manière plus réaliste dans un environnement dynamique. Autre exemple, l'algorithme RVO (<i>Reactive Velocity Obstacles</i>) [Bleiweiss2009] se focalise sur l'évitement dynamique d'obstacles en intégrant le comportement réactif des autres agents et permet de produire des mouvements visuellement très réalistes. Enfin, [Demeulemeester2011] propose un algorithme qui donne la possibilité aux agents de définir des ROI (<i>Region Of Interest</i>) qui évoluent en même temps que les objectifs de ses agents.</p>

            <p>Cette motivation à créer des algorithmes plus génériques se retrouvent aussi auprès des algorithmes spécialisés dans la recherche de voisins. Ce type de calcul étant extrêmement coûteux en temps et en mémoire. [Li2014] propose une stratégie visant à les accélérer grâce au GPGPU et les tests menés ont montré que la solution développée a accéléré de manière significative (89 fois) l'algorithme de recherche comparé à son implémentation sur CPU grâce à une carte Nvidia Tesla K20 GPU et ces 2 496 coeurs CUDA. Ces travaux ont ensuite été améliorés en 2016 [Li2016] avec une meilleure prise en compte des allocations mémoires dynamiques que l'utilisation du GPGPU implique de par son architecture.</p>

            <p>Présents dans de nombreux modèles multi-agents, les algorithmes de navigation ou de recherche de voisins sont un très bon exemple de la réutilisabilité qu'il est possible d'obtenir dès lors que l'on augmente la modularité des solutions trouvées. En effet, en dissociant les algorithmes des comportements des agents, il est alors possible de créer des algorithmes génériques pouvant s'adapter à de nombreux modèles et contextes différents ce qui améliore donc grandement leur réutilisation. Nvidia fournit d'ailleurs une librairie (nvGRAPH) spécialement optimisée pour fonctionner sur les GPU de la marque et dédiée à ce type d'algorithme.</p>

            <h4>Bilan des implémentations tout-sur-GPU</h4>

            <p>Jusqu'à présent, les contributions analysées adoptaient toutes une implémentation <i>tout-sur-GPU</i> qui consiste à exécuter entièrement le modèle sur le GPU. Grâce à cette approche, on a observé, dans l'ensemble, de nettes accélérations des simulations (au minimum deux fois plus rapides qu'une implémentation sur CPU). Ces résultats sont encourageants compte tenu du fait qu'ils ont été obtenus en utilisant seulement des cartes graphiques standards comportant quelques centaines de coeurs. </p>

            <p>Une implémentation tout-sur-GPU est donc intéressante lorsque le but principale est la recherche de performance. Cependant, du fait qu'elle nécessite que le modèle soit entièrement transformé pour pouvoir être exécuté sur le GPU, il est presque impossible de le réutiliser ou bien même de le comprendre car son code devient en grande partie incompréhensible pour toutes personnes n'ayant pas de connaissances solides en GPGPU. Cette approche est donc limitée, d'un point de vue génie logiciel, car elle néglige des aspects tels que la généricité, l'accessibilité et la réutilisabilité que nous avons pourtant défini comme essentielles.</p>

            <p>De plus, implémenter un modèle sur GPU n'implique pas obligatoirement un gain de performance, surtout dans le domaine des simulations multi-agents où la diversité des modèles est très grande. La qualité et les choix d'implémentation impactent directement les résultats et les performances qu'il est possible d'obtenir [Aaby2010]. Ainsi, en dépit d'outils de qualité comme CUDA et OpenCL, effectuer une implémentation GPGPU efficace requiert toujours de prendre en compte les spécificités liées au GPGPU.</p>

            <p>Ces difficultés maintiennent le fiable engouement vis à vis du GPGPU ce qui explique en partie le faible nombre de contributions qui traite de l'utilisation de cette technologie dans un contexte agent. C'est pourquoi il peut être pertinent de trouver des méthodes d'implémentation différentes. </p>

            <p>En effet, considérer une nouvelle approche d'implémentation capable de fournir des outils et framework plus réutilisables, plus modulaires, offrant de bonnes performances et une meilleure accessibilité permettra au GPGPU d'être utilisé par un public plus large. Nous allons voir maintenant que l'approche <i>hybride</i> représente une solution attractive qui permet de répondre aux différents problèmes soulevés jusqu'ici par l'implémentation tout-sur-GPU.</p>

            <br/>
            <div class="block-title">
                <h3>Implémentation hybride</h3>
            </div>

            <p>Contrairement à une approche tout-sur-GPU, l'approche de conception hybride partage l'exécution d'un système multi-agent entre le CPU et le GPU. Ainsi, il est possible de choisir ce qui va être exécuté par le GPU en fonction de la nature des calculs et instructions. Moins performante qu'une approche tout-sur-GPU, l'approche hybride possède cependant de nombreux avantages. </p>

            <div class="portfolio-page-image">
                <img src="./these/images_chap3/Hybride.svg" alt=""/>
            </div>

            <p>Par exemple, [Sano2013] propose un framework visant à aider l'utilisateur dans la conception et le déploiement de simulations dans le domaine du trafic routier. Ce framework est voulu très modulaire et peut faire appel, grâce à l'approche hybride utilisée, à la librairie MAT-Sim (<i>Multi-Agents Transport Simulation</i>) et à des algorithmes parallélisés permettant d'adapter et exécuter automatiquement certains comportements agents les plus gourmands en ressources sur le GPU (comme les algorithmes de navigation). Ainsi, un avantage important de l'approche hybride tient au fait qu'elle autorise une plus grande flexibilité et de nouvelles opportunités pour les modèles agents car elle permet une ouverture sur d'autres technologies déjà existantes et éprouvées.</p>

            <p>Dans [Laville2012], la conversion du modèle <i>Sworm</i> vers une version utilisant le GPGPU passe aussi par une approche hybride. Celle-ci est motivée par le fait que <i>Sworm</i> est une simulation multi-niveaux intégrant deux types d'agents très différents : (1) des agents réactifs (niveau micro) simulés par le GPU et (2) des agents cognitifs (niveau macro) gérés par le CPU. En effet, les agents cognitifs invoquent des processus complexes qui peuvent reposer sur de nombreuses données et beaucoup de structures conditionnelles. De fait, ils ne peuvent généralement pas être portés efficacement sur GPU. Ainsi, en éliminant la contrainte du tout-sur-GPU de devoir transformer entièrement le modèle, l'approche hybride autorise une intégration plus facile d'agents ayant des architectures hétérogènes.</p>

            <p>Un autre exemple de l'intérêt des systèmes hybrides est donné dans [Pavlov2013]. Ces travaux présentent trois approches différentes pour l'implémentation d'un gestionnaire de tâches et d'ordonnancement des actions dans un SMA : (1) approche tout-sur-CPU, (2) approche tout-sur-GPU et (3) approche hybride. Les avantages et inconvénients de chacune des solutions montrent que l'approche <i>hybride</i> est la plus prometteuse pour ce contexte applicatif, car la contrainte d'exécuter des tâches simples et indépendantes n'existe plus. Il faut aussi noter que ces travaux sont les premiers à considérer l'utilisation du GPGPU pour des SMA en dehors d'un contexte de simulation.</p>

            <p>[Michel2013] présente un autre aspect de l'approche hybride. En considérant l'environnement comme une entité active, il est possible de simplifier le processus comportemental des agents. L'idée sous-jacente est que les agents ont finalement besoin de manipuler des percepts de haut niveau pour calculer leur comportement : ils ne sont pas intéressés par les données environnementales de bas niveau qui nécessitent un traitement pour être intelligibles. Il est donc intéressant de soulager les agents de ces traitements et de déléguer à l'environnement, via des modules de calcul GPU, le soin de produire des perceptions de haut niveau à partir des données environnementales brutes [Chang2004, Payet2006]. Cette contribution représente précisément le point de départ de nos travaux présentés dans ce manuscrit de thèse.</p>

            <p>[Laville2014] propose un ensemble d'outils appelé MCMAS (<i>Many Core MAS</i>) dont l'objectif est de faciliter l'implémentation de simulations multi-agents sur des architectures parallèles et ainsi mieux exploiter la puissance de ces dernières. 
            MCMAS est donc une boite à outils composée de fonctions usuelles et de structures de données pouvant être utilisée comme une librairie par les plates-formes SMA existantes afin de simplifier l'adaptation des modèles existants et abstraire l'utilisation du GPU aux utilisateurs. Il est aussi très modulaire car il se veut facilement extensible par l'ajout de <i>plugins</i> afin de lui ajouter des fonctionnalités. Implémenté en Java et OpenCL, MCMAS est un exemple frappant de l'intérêt des approches hybrides. Il permet en effet de faire tourner des modèles (1) entièrement sur GPU, (2) entièrement sur CPU ou (3) en utilisant conjointement le CPU et le GPU.</p>

            <p>Les travaux présentés dans [Ho2015] sont les premiers à examiner la possibilité d'utiliser plusieurs GPU dans le but d'augmenter la scalabilité des modèles agents. Motivés par le besoin évident en terme de visualisation et d'interfaces graphiques dédiées à l'analyse en temps réel des simulations, ces travaux explorent l'implémentation d'un système générique de développement multi-agent utilisant les GPU comme accélérateurs de calcul, le tout porté par un framework écrit en Java et en CUDA basé sur la plateforme MASON [Luke2005] (<i>Multi-Agent Simulator Of Neighborhoods</i>). Ainsi, un framework adapté à l'utilisation de plusieurs GPU ayant la capacité de traiter des données sur plusieurs appareils et offrant également une plus grande accessibilité de programmation a été proposé. Une étude de performance autour de cet outil a montré le potentiel d'accélération de ce dernier en simulant des modèles comportant des millions d'agents. Le gain de performance d'un ordre de grandeur de deux minimum (par rapport à une implémentation CPU) a été obtenu grâce à des cartes Nvidia Tesla K20 (2 496 coeurs CUDA) et Nvidia GeForce GTX 690 (3 072 coeurs CUDA).</p>

            <p>[Shekh2015] propose une simulation à base d'agents dédiée à l'analyse des risques pandémiques autour de la grippe. Cette simulation définit des prévisions de diffusion de la maladie dans le but d'aider les différents acteurs de la santé publique à prendre les bonnes décisions en cas d'urgence. Basée sur une approche hybride capable de déléguer les calculs les plus lourds au GPU, [Shekh2015] discute aussi des stratégies envisageables pour porter des MABS sur un ensemble de GPU et pour améliorer le traitement de données en temps réel. Cette simulation est capable de simuler des populations d'agents très importantes d'environ 100 millions d'individus grâce à plusieurs Nvidia Tesla K20 (2 496 coeurs CUDA).</p>

            <p>Enfin, certaines recherches proposent une architecture logicielle de haut niveau qui se focalise sur le déploiement de SMA sur des systèmes matériels hétérogènes et distribués. Par exemple, dans le contexte des simulations de foules, [Vigueras2010] définit une architecture logicielle divisée en deux parties: l'AS (<i>Action Server</i>) et le CP (<i>Client Process</i>). L'AS doit prendre en charge le calcul de la simulation pendant que le CP s'occupe de la gestion du comportement des agents et de leurs états. On voit ici que la flexibilité d'une approche <i>hybride</i> permet de considérer des systèmes beaucoup plus évolués en termes de fonctionnalités et d'architectures logicielles.</p>

            <br/>
            <div class="block-title">
                <h3>Synthèse de l'utilisation du GPGPU dans les MABS</h3>
            </div>

            <table>
                <tbody>
                    <tr>
                        <td><b>Référence</b></td>
                        <td><b>Approche</b></td>
                        <td><b>Implémentation</b></td>
                        <td><b>Type d'agent</b></td>
                        <td><b>GPU</b></td>
                        <td><b>Densité d'agent</b></td>
                    </tr>
                    <tr>
                        <td>[D'Souza2007]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>Fonctions graphiques</td>
                        <td>Réactif</td>
                        <td>128 coeurs</td>
                        <td>1 000 000</td>
                    </tr>
                    <tr>
                        <td>[Lysenko2008]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>Fonctions graphiques</td>
                        <td>Réactif</td>
                        <td>128 coeurs</td>
                        <td>1 000 000</td>
                    </tr>
                    <tr>
                        <td>[RichmondDaniela2008]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>Fonctions graphiques</td>
                        <td>Réactif</td>
                        <td>112 coeurs</td>
                        <td>100 000</td>
                    </tr>
                    <tr>
                        <td>[Perumalla2008]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>Fonctions graphiques</td>
                        <td>Réactif</td>
                        <td>112 coeurs</td>
                        <td>1 000 000</td>
                    </tr>
                    <tr>
                        <td>[Erra2009]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td>Réactif</td>
                        <td>128 coeurs</td>
                        <td>1 000 000</td>
                    </tr>
                    <tr>
                        <td>[Bleiweiss2009]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td></td>
                        <td>240 coeurs</td>
                        <td>100 000</td>
                    </tr>
                    <tr>
                        <td>[Fischer2009]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td></td>
                        <td>256 coeurs</td>
                        <td>10 000</td>
                    </tr>
                    <tr>
                        <td>[Richmond2010]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>256 coeurs</td>
                        <td>100 000</td>
                    </tr>
                    <tr>
                        <td>[Husselmann2011]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>512 coeurs</td>
                        <td>10 000</td>
                    </tr>
                    <tr>
                        <td>[Richmond2011]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>96 coeurs</td>
                        <td>10 000</td>
                    </tr>
                    <tr>
                        <td>[Laville2012]</td>
                        <td><i>Hybride</i></td>
                        <td>C + OpenCL</td>
                        <td>Réactif et cognitif</td>
                        <td>240 coeurs</td>
                        <td>1 000</td>
                    </tr>
                    <tr>
                        <td>[Pavlov2013]</td>
                        <td><i>Hybride</i></td>
                        <td>C + CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>[Michel2013]</td>
                        <td><i>Hybride</i></td>
                        <td>Java + CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>256 coeurs</td>
                        <td>1 000</td>
                    </tr>
                    <tr>
                        <td>[Laville2014]</td>
                        <td><i>Hybride</i></td>
                        <td>CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>240 coeurs</td>
                        <td>1 000</td>
                    </tr>
                    <tr>
                        <td>[Ho2015]</td>
                        <td><i>Hybride</i></td>
                        <td>CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>2 496 coeurs</td>
                        <td>1 000 000</td>
                    </tr>
                    <tr>
                        <td>[Chen2015]</td>
                        <td><i>Tout-sur-GPU</i></td>
                        <td>C++ + CUDA</td>
                        <td>Réactif et cognitif</td>
                        <td>512 coeurs</td>
                        <td>10 000</td>
                    </tr>
                    <tr>
                        <td>[Shekh2015]</td>
                        <td><i>Hybride</i></td>
                        <td>C + CUDA et OpenCL</td>
                        <td>Réactif et cognitif</td>
                        <td>2 496 coeurs</td>
                        <td>100 000 000</td>
                    </tr>
                </tbody>
            </table>


            <p>De cet état de l'art, il est clair que le GPGPU représente une technologie d'avenir pour les simulations multi-agents mais aussi pour les SMA. Pourtant, il est également évident que l'utilisation de cette technologie dans le cadre d'une programmation orientée agent reste une tâche difficile. Nous discernons deux raisons principales qui expliquent ces difficultés : (1) le faible degré de généricité des modèles considérés (et la faible réutilisabilité qui en découle) et (2) le manque d'accessibilité des frameworks existants. Ces deux problématiques ont d'ailleurs été identifiées dans [Holk2011] et [Bourgoin2013-2] comme cruciales pour le développement du GPGPU en général. Dans cette section, nous proposons une étude des différents travaux présentés précédemment à l'égard de la façon dont ils ont tenu compte de ces deux aspects.</p>

            <h4>Nature et généricité des modèles</h4>

            <p>La nature des modèles de SMA utilisant le GPGPU est fortement liée à l'évolution de cette technologie et des outils associés. En 2008, le faible nombre de contributions pouvait s'expliquer par : (1) la complexité à modéliser des SMA en utilisant directement les fonctions graphiques et (2) les limitations du matériel alors disponible (taille mémoire, bande passante, etc.). 
            Sans surprise, au vue des difficultés énoncées, la très grande majorité des modèles implémentés sur GPU mettait en scène des agents purement réactifs évoluant dans des environnements minimalistes. Dans ce contexte, ABGPU a été le premier framework à mettre en avant la généricité en généralisant des comportements agents communs [RichmondDaniela2008].</p>

            <p>Avec la sortie de CUDA et d'OpenCL, le nombre de contributions a considérablement augmenté. Mais, malgré la simplification importante apportée par ces outils, peu de travaux ont porté leur attention sur l'amélioration de la généricité. De fait, l'augmentation des performances reste la motivation première et la plupart des implémentations se font de zéro, limitant donc le modèle agent produit au domaine pour lequel il a été créé. </p>

            <p>Flame GPU est une exception remarquable car il fournit des modèles d'agents prédéfinis qui peuvent être adaptés à différents domaines d'application tels que la biologie (<i>e.g.</i> [Richmond2009a] et [Richmond2010]) ou les sciences comportementales (<i>e.g.</i> [Karmakharm2010]). </p>

            <p>Cependant, on peut tout de même remarquer que la complexité des modèles agents proposés augmente et que certains travaux reposent sur des architectures cognitives (<i>e.g.</i> [Richmond2011]) ou hétérogènes (<i>e.g.</i> [D'Souza2009] et [Husselmann2011]).</p>

            <p>Par ailleurs, grâce au haut niveau de gestion des données mis en place dans CUDA et OpenCL, il est devenu possible de séparer plus facilement le modèle agent de celui de l'environnement afin de lui attribuer un véritable rôle, notamment en le rendant actif dans le processus de simulation comme c'est le cas dans les simulations de foules avec la gestion (1) de forces sociales [Richmond2011] et (2) d'algorithmes de mouvement [Bleiweiss2009, Fischer2009, Demeulemeester2011]. Grâce à cette séparation, ces derniers travaux représentent d'importantes contributions du point de vue de la généricité car ils se concentrent sur la généralisation d'algorithmes pouvant être appliqués dans plusieurs domaines.</p>

            <p>L'approche hybride permet de faire un pas en avant vers la réalisation de modèles agents plus complexes. Tout d'abord, cette approche permet de créer plus facilement des modèles dans lesquels les agents vont avoir des architectures différentes (par exemple cognitive et réactive [Laville2012]). Deuxièmement, une approche hybride possède une grande modularité ce qui facilite, entre autres, la séparation explicite entre agents et environnements.</p>

            <p>Ainsi, même si le caractère générique n'est pas nécessairement un objectif explicite des systèmes hybrides, il est clair que cette approche présente une architecture logicielle la plus à même de fournir le cadre nécessaire à une meilleure intégration du GPGPU dans les simulations multi-agents grâce à la modularité et à la réutilisabilité qu'elle permet. La librairie MCMAS [Laville2014] en est d'ailleurs un exemple marquant.</p>

            <h4>L'accessibilité des modèles</h4>

            <p>La nécessité de simplifier l'utilisation et la programmation sur GPU est très vite devenue une évidence et cela dès l'émergence de cette technologie comme expliqué dans [Perumalla2008]. [Lysenko2008] et ABGPU [RichmondDaniela2008] sont les premières contributions à considérer l'accessibilité comme un critère essentiel. En effet, ces travaux avaient pour ambition de ne requérir que peu de connaissances en GPGPU car ils fournissaient des fonctions GPU prédéfinies de haut niveau, directement utilisables depuis le langage C/C++. Cependant, malgré les efforts d'abstraction réalisés, l'objectif n'a pas été atteint.</p>

            <p>Par la suite, bien que CUDA et OpenCL aient grandement simplifié l'utilisation du GPGPU, l'accessibilité des solutions créées est restée une problématique secondaire et la majorité des travaux requièrent toujours des connaissances importantes en GPGPU. Il faut cependant noter les orientations prises par certains travaux liés à la simulation de foules et de trafics. En travaillant sur la réutilisation des outils créés (<i>e.g.</i> algorithmes de PathPlanning [Fischer2009, Bleiweiss2009, Demeulemeester2011]), ces travaux font un pas certain vers une accessibilité renforcée en insistant sur la capitalisation des efforts passés, et donc sur la réutilisation via la constitution de bibliothèques d'algorithmes s'exécutant sur le GPU et spécifiquement dédiées au monde SMA.</p>

            <p>C'est d'ailleurs sous cette forme, de bibliothèques prêtes à l'emploi, que de nombreux domaines utilisent le GPGPU. On peut citer pour exemple les librairies Nvidia CuBLAS (<i>Compute Unified Basic Linear Algebra Subprograms</i>) et NPP (<i>Nvidia Performance Primitives</i>) spécialisées dans le traitement de signaux, d'images et de vidéos ou encore cuFFT (<i>CUDA Fast Fourier Transform</i>) pour le calcul des transformées de Fourier. Elles sont très abouties et leur utilisation est largement répandue dans leurs communautés respectives.</p>

            <p>L'approche hybride constitue encore une fois une piste très intéressante en ce qui concerne l'accessibilité. Tout d'abord, elle s'accorde naturellement bien avec une vision modulaire du modèle et de son implémentation, et donc avec l'idée de librairie réutilisable, comme c'est le cas avec MCMAS [Laville2014]. Mais aussi, de par son ouverture aux autres technologies, elle lève une partie des contraintes du tout-sur-GPU (<i>e.g.</i> [Laville2012] et [Michel2013], utilisation de la programmation orientée objet en parallèle du GPGPU).</p>

            <br/>
            <div class="block-title">
                <h3>Problématiques abordées dans la thèse</h3>
            </div>

            <p>Nous présentions le GPGPU comme une technologie très intéressante pour toutes les applications où le temps d'exécution et/ou les aspects temps réels sont cruciaux. De l'état de l'art mené dans ce chapitre sur les contributions associant les simulations multi-agents avec le calcul sur carte graphique, nous observons que l'utilisation du GPGPU permet de prendre en considération les problèmes de passage à l'échelle telles que les difficultés de gérer des nombres d'agents de plus en plus importants et/ou des environnements de plus en plus grands dans des systèmes aux ressources souvent limités. De plus, les travaux sur l'utilisation du GPGPU pour l'allocation de tâches, réalisés dans [Pavlov2013], sont une exception notable qui préfigure du fait que le GPGPU peut aussi apporter beaucoup au domaine des SMA en général.</p>

            <p>Cependant, nous observons aussi que, malgré les possibilités offertes par le GPGPU, le nombre de publications mêlant GPGPU et simulations multi-agents (ou plus généralement systèmes multi-agents) est toujours très faible comparé à d'autres domaines de recherches. Alors que les contributions traitant du GPGPU et du GPGPU dans la simulation possède un profil de publications (nombre de publications par année) assez similaire (forte accélération à partir de 2007), les travaux mêlant GPGPU et agents peinent à décoller. Il existe donc un réel problème d'appropriation de cette technologie par la communauté agent. </p>

            <p>A l'image des travaux de Bourgoin [Bourgoin2013-2] qui référencent l'accessibilité et la généricité comme critères essentiels pour un bon usage du GPGPU, nous retrouvons les mêmes perspectives pour l'utilisation du GPGPU dans le domaine des SMA. Ces perspectives nous ont permis d'identifier deux principaux facteurs limitant l'essor de l'utilisation du GPGPU dans notre communauté : (1) sa difficulté d'implémentation amplifiée par son manque d'accessibilité et (2) le fait que la grande majorité des travaux de recherche traitant de l'utilisation de la programmation GPGPU pour les MABS se focalisent uniquement sur la recherche de performance et sont ainsi très difficilement réutilisables en l'état.</p>

            <p>Ces difficultés ont d'ailleurs déjà été évoquées en 2008 par Perumalla et Aaby qui avaient conclu à l'époque que l'augmentation des performances grâce au GPGPU ne pouvait se faire qu'au détriment de la modularité, réutilisabilité et de l'accessibilité des solutions développées [Perumalla2008]. Depuis cette étude et malgré les évolutions notables des cartes graphiques et des interfaces de programmation dédiées, le constat reste le même et les limites énoncées perdurent.</p>

            <p>Ainsi, les différents travaux de recherche s'intéressant à l'utilisation du GPGPU pour la simulation multi-agent sont toujours divisés en deux catégories distinctes : (1) celle des travaux ne se focalisant que sur la recherche de performance pure et (2) celle des travaux visant à prendre en considération les problèmes d'accessibilité, de réutilisabilité et de programmabilité. Les contributions de cette deuxième catégorie sont, pour la plupart, basées sur une approche hybride qui représente, comme nous l'avons vu précédemment, l'approche la plus prometteuse dans la résolution des différentes limites du GPGPU dans un contexte agent. Cependant, la grande majorité de ces travaux proposent des solutions et outils qui cachent l'utilisation de cette technologie. En effet, le recours au GPGPU se fait de manière transparente pour l'utilisateur.</p>

            <p>Au vu de ces différentes conclusions, nous pouvons constater que :</p>
            <ul>
            <li><p> La proportion de travaux traitant de l'utilisation du GPGPU dans les MABS reste toujours très faible alors que le besoin en ressource de calcul ne cesse d'augmenter.</p></li>
            <li><p> Une très grande majorité des travaux essayant d'améliorer l'accessibilité, la généricité et la réutilisabilité du GPGPU considèrent uniquement une utilisation transparente de cette technologie limitant de ce fait le champ d'application des solutions proposées.</p></li>
            </ul>

            <p>Ainsi, nous choisissons, dans la suite de ce document, d'explorer une autre piste de recherche. Plutôt que de se focaliser sur l'accessibilité, la réutilisabilité et la généricité des solutions via une utilisation transparente du GPGPU, nous proposons d'utiliser une approche de conception permettant d'adapter et transformer un modèle agent afin qu'il tire partie des architectures massivement parallèles (et donc des GPU) mais sans cacher la technologie sous-jacente.</p>

            <br/>

            <div id="chart_chap3" class="chart"></div>

            <div class="ajax-page-nav">
                <div class="nav-item ajax-page-prev-next">
                    <a class="ajax-page-load" href="./these/t_chap2.html"><i class="pe-7s-icon pe-7s-angle-left"></i></a>
                    <a class="ajax-page-load" href="./these/t_chap4.html"><i class="pe-7s-icon pe-7s-angle-right"></i></a>
                </div>
                <div class="nav-item ajax-page-close-button">
                    <a id="ajax-page-close-button" href="#"><i class="pe-7s-icon pe-7s-close"></i></a>
                </div>
            </div>   

            <script type="text/javascript">
                    function customAjaxScroll() {
                        var windowWidth = $(window).width();
                        if (windowWidth > 991) {
                            // Custom Ajax Page Scroll
                            $("#ajax-page").mCustomScrollbar({
                                scrollInertia: 8,
                                documentTouchScroll: false
                            });
                        } else {
                            $("#ajax-page").mCustomScrollbar('destroy');
                        }
                    }

                    jQuery(document).ready(function($){

                        // Ajax Loaded Page Scroll
                        customAjaxScroll();

                        Highcharts.chart('chart_chap3', {
                            title: {
                                text: 'Nombre de publications par mots-clés'
                            },
                            subtitle: {
                                text: 'Source: Google Scholar'
                            },
                            yAxis: {
                                title: {
                                    text: 'Nombre de publications'
                                }
                            },
                            legend: {
                                layout: 'vertical',
                                align: 'right',
                                verticalAlign: 'middle'
                            },
                            plotOptions: {
                                series: {
                                    pointStart: 2001
                                }
                            },
                            series: [{
                                name: 'GPGPU et multi-agent',
                                data: [1,2,1,3,3,17,32,62,107,137,282,274,431,341,434]
                            }, {
                                name: 'GPGPU et simulation',
                                data: [4,3,10,45,120,166,274,439,734,1030,1530,1650,2000,1930,1950]
                            }, {
                                name: 'GPGPU',
                                data: [10,10,31,102,227,313,578,952,2620,4090,5900,7310,8190,8430,8000]
                            }]

                        });


                        $('.portfolio-page-carousel').owlCarousel({
                            smartSpeed:1200,
                            items: 1,
                            loop: true,
                            dots: true,
                            nav: true,
                            navText: false,
                            margin: 10
                        });

                    });

                    jQuery(window).on('resize', function() {
                        customAjaxScroll();
                    });

            </script>
        </div>
    </div>
</div>
